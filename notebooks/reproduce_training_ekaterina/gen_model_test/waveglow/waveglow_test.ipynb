{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "# dep: git clone https://github.com/NVIDIA/waveglow\n",
    "from waveglow import glow\n",
    "import os\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# test with a pre-trained model\n",
    "class BirdSoundDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, sr=22050, n_mels=80, hop_length=256):\n",
    "        self.data_dir = data_dir\n",
    "        self.wav_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.wav')]\n",
    "        self.sr = sr\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sr, n_mels=n_mels, hop_length=hop_length\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wav_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav_file = self.wav_files[idx]\n",
    "        waveform, _ = torchaudio.load(wav_file)\n",
    "        mel_spectrogram = self.mel_transform(waveform)\n",
    "        return mel_spectrogram\n",
    "\n",
    "data_dir = \"D:/data\"\n",
    "dataset = BirdSoundDataset(data_dir)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow')\n",
    "waveglow.eval()\n",
    "\n",
    "for m in waveglow.modules():\n",
    "    if 'Conv' in str(type(m)):\n",
    "        torch.nn.utils.remove_weight_norm(m)\n",
    "\n",
    "\n",
    "def generate_audio(mel_spectrogram, waveglow_model, output_dir, filename='generated_sample.wav'):\n",
    "    mel_spectrogram = mel_spectrogram.cuda()\n",
    "    waveglow_model = waveglow_model.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        audio = waveglow_model.infer(mel_spectrogram, sigma=0.6)\n",
    "\n",
    "    audio = audio.cpu().numpy().astype(np.float32)\n",
    "    audio = audio.squeeze()\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    write(output_path, 22050, audio)\n",
    "\n",
    "for idx, mel_spec in enumerate(dataloader):\n",
    "    generate_audio(mel_spec, waveglow, output_dir=\"./gen_sample\", filename=f'bird_sound_{idx}.wav')\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-08-12T16:31:23.099996Z"
    }
   },
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, residual_channels, skip_channels, dilation_channels, n_layers, n_blocks, input_channels=256):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.residual_channels = residual_channels\n",
    "        self.skip_channels = skip_channels\n",
    "        self.dilation_channels = dilation_channels\n",
    "        self.n_layers = n_layers\n",
    "        self.n_blocks = n_blocks\n",
    "\n",
    "        self.dilations = [2 ** i for i in range(n_layers)] * n_blocks\n",
    "\n",
    "        self.input_conv = nn.Conv1d(input_channels, residual_channels, kernel_size=1)\n",
    "        self.residual_layers = nn.ModuleList()\n",
    "        self.skip_layers = nn.ModuleList()\n",
    "\n",
    "        for dilation in self.dilations:\n",
    "            self.residual_layers.append(\n",
    "                nn.Conv1d(residual_channels, dilation_channels, kernel_size=2, dilation=dilation)\n",
    "            )\n",
    "            self.skip_layers.append(\n",
    "                nn.Conv1d(dilation_channels, skip_channels, kernel_size=1)\n",
    "            )\n",
    "\n",
    "        self.output_conv1 = nn.Conv1d(skip_channels, skip_channels, kernel_size=1)\n",
    "        self.output_conv2 = nn.Conv1d(skip_channels, input_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_conv(x)\n",
    "        skip = 0\n",
    "\n",
    "        for residual_layer, skip_layer in zip(self.residual_layers, self.skip_layers):\n",
    "            residual = residual_layer(x)\n",
    "            skip += skip_layer(residual)\n",
    "            x = x + residual\n",
    "\n",
    "        x = torch.relu(skip)\n",
    "        x = torch.relu(self.output_conv1(x))\n",
    "        x = self.output_conv2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "hsn = load_dataset('DBD-research-group/BirdSet', 'HSN')\n",
    "\n",
    "subset_percentage = 0.05  # 25%\n",
    "subset_indices = random.sample(range(len(hsn['train'])), int(len(hsn['train']) * subset_percentage))\n",
    "hsn = hsn['train'].select(subset_indices)\n",
    "print(len(subset_indices))\n",
    "\n",
    "def preprocess(batch):\n",
    "    audio_tensors = []\n",
    "    audio, _ = torchaudio.load(batch['filepath'][0])\n",
    "    audio_tensors.append(audio)\n",
    "    return {'audio': audio_tensors}\n",
    "\n",
    "\n",
    "hsn = hsn.map(preprocess, batched=True, batch_size=1)\n",
    "print(hsn)\n",
    "\n",
    "residual_channels = 32\n",
    "skip_channels = 512\n",
    "dilation_channels = 32\n",
    "n_layers = 10\n",
    "n_blocks = 3\n",
    "\n",
    "model = WaveNet(residual_channels, skip_channels, dilation_channels, n_layers, n_blocks)\n",
    "\n",
    "print(hsn['audio'])\n",
    "audio_data = hsn['audio'].unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    generated_audio = model(audio_data)\n",
    "\n",
    "torchaudio.save('generated_bird_sound.wav', generated_audio.squeeze(0), sample_rate=22050)\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45018701ce5b4e7a915a69e30cc764d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19959a4167c34b16b5d1fe369d438ae0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/146k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c9668b893be4cfea8210ff21edff5e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/10.8k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfbdd79557734c47a4b01e3f64d38903"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.08G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d40b6725b4f4431f941f8f082ba74a35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bde9d465161744f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
